{
  "name": "bigml",
  "description": "Node bindings for BigML.",
  "tags": [
    "REST",
    "api",
    "bindings",
    "BigML"
  ],
  "version": "0.2.0",
  "author": {
    "name": "BigML",
    "email": "info@bigml.com"
  },
  "repository": {
    "type": "git",
    "url": "http://github.com/bigmlcom/bigml-node"
  },
  "engines": [
    "node >= 0.10.0"
  ],
  "main": "index.js",
  "dependencies": {
    "request": "2.21.0",
    "winston": "0.7.1",
    "form-data": "0.0.10",
    "combined-stream": "0.0.4",
    "mime": "1.2.2",
    "async": "0.2.7"
  },
  "scripts": {
    "test": "mocha -t 20000"
  },
  "readme": "BigML Node.js Bindings\n======================\n\n[BigML](https://bigml.com) makes machine learning easy by taking care\nof the details required to add data-driven decisions and predictive\npower to your company. Unlike other machine learning services, BigML\ncreates\n[beautiful predictive models](https://bigml.com/gallery/models) that\ncan be easily understood and interacted with.\n\nThese BigML Node.js bindings allow you to interact with BigML.io, the API\nfor BigML. You can use it to easily create, retrieve, list, update, and\ndelete BigML resources (i.e., sources, datasets, models and\npredictions).\n\nThis module is licensed under the [Apache License, Version\n2.0](http://www.apache.org/licenses/LICENSE-2.0.html).\n\nSupport\n-------\n\nPlease report problems and bugs to our [BigML.io issue\ntracker](https://github.com/bigmlcom/io/issues).\n\nDiscussions about the different bindings take place in the general\n[BigML mailing list](http://groups.google.com/group/bigml). Or join us\nin our [Campfire chatroom](https://bigmlinc.campfirenow.com/f20a0).\n\nRequirements\n------------\n\nNode 0.10 is currently supported by these bindings.\n\nThe only mandatory third-party dependencies are the\n[request](https://github.com/mikeal/request.git),\n[winston](https://github.com/flatiron/winston.git) and\n[form-data](https://github.com/felixge/node-form-data.git) libraries.\n\nThe testing environment requires the additional \n[mocha](https://github.com/visionmedia/mocha) package that can be installed\nwith the following command:\n\n    $ sudo npm install -g mocha\n\nInstallation\n------------\n\nTo install the latest stable release with\n[npm](https://npmjs.org/):\n\n    $ npm install bigml\n\nYou can also install the development version of the bindings by cloning the\nGit repository to your local computer and issuing:\n\n    $ npm install .\n\nTesting\n-------\n\nThe test suite is run automatically using `mocha` as test framework. As all the\ntested api objects perform one or more connections to the remote resources in\nbigml.com, you may have to enlarge the default timeout used by `mocha` in\neach test. For instance:\n\n    $ mocha -t 20000\n\nwill set the timeout limit to 20 seconds. This limit should typically be\nenough, but you can change it to fit the latencies of your connection.\n\nImporting the modules\n---------------------\n\nTo use the library, import it with `require`:\n\n    $ node\n    > bigml = require('bigml');\n\nthis will give you access to the following library structure:\n\n    - bigml.constants       common constants\n    - bigml.BigML           connection object\n    - bigml.Resource        common API methods\n    - bigml.Source          Source API methods\n    - bigml.Dataset         Dataset API methods\n    - bigml.Model           Model API methods\n    - bigml.Ensemble        Ensemble API methods\n    - bigml.Prediction      Prediction API methods\n    - bigml.Evaluation      Evaluation API methods\n    - bigml.LocalModel      Model for local predictions\n    - bigml.LocalEnsemble   Ensemble for local predictions\n\n\nAuthentication\n--------------\n\nAll the requests to BigML.io must be authenticated using your username\nand [API key](https://bigml.com/account/apikey) and are always\ntransmitted over HTTPS.\n\nThis module will look for your username and API key in the environment\nvariables `BIGML_USERNAME` and `BIGML_API_KEY` respectively. You can \nadd the following lines to your `.bashrc` or `.bash_profile` to set\nthose variables automatically when you log in::\n\n    export BIGML_USERNAME=myusername\n    export BIGML_API_KEY=ae579e7e53fb9abd646a6ff8aa99d4afe83ac291\n\nWith that environment set up, connecting to BigML is a breeze::\n\n    connection = new bigml.BigML();\n\nOtherwise, you can initialize directly when instantiating the BigML\nclass as follows::\n\n    connection = new bigml.BigML('myusername',\n                                 'ae579e7e53fb9abd646a6ff8aa99d4afe83ac291')\n\nAlso, you can initialize the library to work in the Sandbox environment by\nsetting the third parameter `devMode` to `true`::\n\n    connection = new bigml.BigML('myusername',\n                                 'ae579e7e53fb9abd646a6ff8aa99d4afe83ac291',\n                                 true)\n\nQuick Start\n-----------\n\nLet's see the steps that will lead you from [this csv\nfile](https://static.bigml.com/csv/iris.csv) containing the [Iris\nflower dataset](http://en.wikipedia.org/wiki/Iris_flower_data_set) to\npredicting the species of a flower whose `sepal length` is `5` and\nwhose `sepal width` is `2.5`. By default, BigML considers the last field\n(`species`) in the row as the\nobjective field (i.e., the field that you want to generate predictions\nfor). The csv structure is::\n\n    sepal length,sepal width,petal length,petal width,species\n    5.1,3.5,1.4,0.2,Iris-setosa\n    4.9,3.0,1.4,0.2,Iris-setosa\n    4.7,3.2,1.3,0.2,Iris-setosa\n    ...\n\nThe steps required to generate a prediction are creating a set of\nsource, dataset and model objects::\n\n```js\n    var bigml = require('bigml');\n    var source = new bigml.Source();\n    source.create('./data/iris.csv', function(error, sourceInfo) {\n      if (!error && sourceInfo) {\n        var dataset = new bigml.Dataset();\n        dataset.create(sourceInfo, function(error, datasetInfo) {\n          if (!error && datasetInfo) {\n            var model = new bigml.Model();\n            model.create(datasetInfo, function (error, modelInfo) {\n              if (!error && modelInfo) {\n                var prediction = new bigml.Prediction();\n                prediction.create(modelInfo, {'petal length': 1})\n              }\n            });\n          }\n        });\n      }\n    });\n```\n\nNote that in our example the `prediction.create` call has no associated\ncallback. All the CRUD methods of any resource allow assigning a callback as\nthe last parameter,\nbut if you don't the default action will be\nprinting the resulting resource or the error. For the `create` method:\n\n    > result: \n    { code: 201,\n      object: \n       { category: 0,\n         code: 201,\n         content_type: 'text/csv',\n         created: '2013-06-08T15:22:36.834797',\n         credits: 0,\n         description: '',\n         fields_meta: { count: 0, limit: 1000, offset: 0, total: 0 },\n         file_name: 'iris.csv',\n         md5: 'd1175c032e1042bec7f974c91e4a65ae',\n         name: 'iris.csv',\n         number_of_datasets: 0,\n         number_of_ensembles: 0,\n         number_of_models: 0,\n         number_of_predictions: 0,\n         private: true,\n         resource: 'source/51b34c3c37203f4678000020',\n         size: 4608,\n         source_parser: {},\n         status: \n          { code: 1,\n            message: 'The request has been queued and will be processed soon' },\n         subscription: false,\n         tags: [],\n         type: 0,\n         updated: '2013-06-08T15:22:36.834844' },\n      resource: 'source/51b34c3c37203f4678000020',\n      location: 'https://localhost:1026/andromeda/source/51b34c3c37203f4678000020',\n      error: null }\n\n\nThe generated objects can be retrieved, updated and deleted through the\ncorresponding REST methods. For instance, in the previous example you would\nuse:\n\n```js\n    bigml = require('bigml');\n    var source = new bigml.Source();\n    source.get('source/51b25fb237203f4410000010' function (error, resource) {\n        if (!error && resource) {\n          console.log(resource);\n        }\n      })\n```\nto recover and show the source information.\n\nYou can also generate local predictions using the information of your\nmodels::\n\n```js\n    bigml = require('bigml');\n    var localModel = new bigml.LocalModel('model/51922d0b37203f2a8c000010');\n    localModel.predict({'petal length': 1},\n                       function(error, prediction) {console.log(prediction)});\n```\n\nAnd similarly, for your ensembles\n\n```js\n    bigml = require('bigml');\n    var localEnsemble = new bigml.LocalEnsemble('ensemble/51901f4337203f3a9a000215');\n    localEnsemble.predict({'petal length': 1}, 0, \n                          function(error, prediction) {console.log(prediction)});\n```\n\nwill generate a prediction by combining the predictions of each of the models\nthey enclose. The example uses the `plurality` combination method (whose code\nis `0`. Check the docs for more information about the available combination\nmethods).\n\nAdditional Information\n----------------------\n\nWe've just drawn a first sketch. For additional information, see\nthe files included in the [docs folder](./doc/index.md).\n\nHow to Contribute\n-----------------\n\nPlease follow these steps:\n\n  1. Fork the project on github.com.\n  2. Create a new branch.\n  3. Commit changes to the new branch.\n  4. Send a [pull request](https://github.com/bigmlcom/bigml-node/pulls).\n\n\nFor details on the underlying API, see the\n[BigML API documentation](https://bigml.com/developers).\n",
  "readmeFilename": "README.md",
  "_id": "bigml@0.2.0",
  "dist": {
    "shasum": "03d292747db3bec5d558e734e4b1265e9cf8b934"
  },
  "_from": "bigml@",
  "_resolved": "https://registry.npmjs.org/bigml/-/bigml-0.2.0.tgz"
}
